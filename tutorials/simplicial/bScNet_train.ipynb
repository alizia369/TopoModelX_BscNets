{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Block simplicial complex neural networks (BScNets)\n",
    "\n",
    "In this notebook, we will create and train Block simplicial complex neural networks, as proposed in the paper by [Yuzhou Chen, Yulia R Gel and H Vincent Poor. BScNets: Block simplicial complex neural networks. Proceedings of the AAAI Conference on Artificial Intelligence. 2022]. \n",
    "\n",
    "We train the model to perform Cora benchmark dataset. \n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r \\rightarrow r)} = (H_r)\\_{xy} \\cdot h_{{y}}^{t, (r)} \\cdot \\Theta^{t,(r \\rightarrow r)}$\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r \\rightarrow r')} = (G_{r \\rightarrow r'})\\_{xy} \\cdot h^{t, (r)}\\_y \\cdot \\Theta^{t,(r \\rightarrow r')}$\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = (G{r' \\rightarrow r})\\_{xy} \\cdot h_y^{t,(r')} \\cdot \\Theta^{t,(r' \\rightarrow r)}$\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r')}  = (H_{r'})\\_{xy} \\cdot h_{{y}}^{t,(r')} \\cdot \\Theta^{t,(r' \\rightarrow r')}$\n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)} = \\sum_{y \\in \\mathcal{N}\\_\\uparrow(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(r \\rightarrow r')}  = \\sum_{y \\in \\mathcal{N}\\_\\downarrow(x)} m_{y \\rightarrow x}^{(r \\rightarrow r')}$\n",
    "\n",
    "游릲 $\\quad m_x^{(r \\rightarrow r)}  = \\sum_{y \\in (\\mathcal{L}\\_\\uparrow+\\mathcal{L}\\_\\downarrow)(x)} m_{y \\rightarrow x}^{(r \\rightarrow r)}$\n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r')}  = \\sum_{y \\in (\\mathcal{L}\\_\\uparrow+\\mathcal{L}\\_\\downarrow)(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r')}$\n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r \\rightarrow r)}+ m_x^{(r' \\rightarrow r)}$\n",
    "\n",
    "游릴 $\\quad m_x^{(r')}  = m_x^{(r' \\rightarrow r')} + m_x^{(r \\rightarrow r')}$\n",
    "\n",
    "游릱 $\\quad h^{t+1, (r)}\\_x  = \\sigma(m_x^{(r)})$\n",
    "\n",
    "游릱 $\\quad h^{t+1, (r')}\\_x = \\sigma(m_x^{(r')})$\n",
    "\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets.graph as graph\n",
    "import torch_geometric\n",
    "\n",
    "# from topomodelx.nn.simplicial.hsn_layer import HSNLayer\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# import loaddatas as lds\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import topomodelx.nn.simplicial.bScNet_layer as bScLayer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch.nn.init import xavier_normal_ as xavier\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "# print(dataset)\n",
    "# Cora Dataset\n",
    "dataset = torch_geometric.datasets.Planetoid(\n",
    "    root=\"tmp/Cora\", name=\"Cora\", transform=T.NormalizeFeatures()\n",
    ")\n",
    "\n",
    "data = dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Cora\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "tensor(1862)\n"
     ]
    }
   ],
   "source": [
    "# Check Cora data\n",
    "print(dataset.num_classes)\n",
    "print(dataset.name)\n",
    "print(data)\n",
    "print(data.edge_index[1][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilizing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zia003\\OneDrive - CSIRO\\CSIRO work\\Code\\TopoX ICML 2003 challenge\\TopoModelX\\topomodelx\\nn\\simplicial\\bScNet_layer.py:407: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(g)\n",
      "C:\\Users\\zia003\\OneDrive - CSIRO\\CSIRO work\\Code\\TopoX ICML 2003 challenge\\TopoModelX\\topomodelx\\nn\\simplicial\\bScNet_layer.py:506: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  nx.incidence_matrix(G, nodelist=V, edgelist=E, oriented=True).todense()\n",
      "C:\\Users\\zia003\\OneDrive - CSIRO\\CSIRO work\\Code\\TopoX ICML 2003 challenge\\TopoModelX\\topomodelx\\nn\\simplicial\\bScNet_layer.py:204: RuntimeWarning: invalid value encountered in matmul\n",
      "  L0u = B1.T @ B1  # B1 @ D3_n @ B1.T @ inv(D2_1)\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "model, data = locals()[\"bScLayer\"].call(\n",
    "    data, dataset.name, data.x.size(1), dataset.num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        xavier(m.weight)\n",
    "        if not m.bias is None:\n",
    "            torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(weights_init)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0)\n",
    "best_val_acc = test_acc_same = test_acc_diff = test_acc = 0.0\n",
    "best_val_roc = test_roc_same = test_roc_diff = test_roc = 0.0\n",
    "best_val_loss = np.inf\n",
    "# train and val/test\n",
    "wait_step = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is: 1\n",
      "0.6203863002211973\n",
      "epoch is: 2\n",
      "0.6203863002211973\n",
      "epoch is: 3\n",
      "0.6203863002211973\n",
      "epoch is: 4\n",
      "0.6203863002211973\n",
      "epoch is: 5\n",
      "0.6203863002211973\n",
      "epoch is: 6\n",
      "0.6203863002211973\n",
      "epoch is: 7\n",
      "0.6203863002211973\n",
      "epoch is: 8\n",
      "0.6203863002211973\n",
      "epoch is: 9\n",
      "0.6203863002211973\n",
      "epoch is: 10\n",
      "0.6203863002211973\n",
      "epoch is: 11\n",
      "0.6543393716838468\n",
      "epoch is: 12\n",
      "0.6946753603492895\n",
      "epoch is: 13\n",
      "0.7057207708655612\n",
      "epoch is: 14\n",
      "0.7089881305208982\n",
      "epoch is: 15\n",
      "0.7089881305208982\n",
      "epoch is: 16\n",
      "0.7089881305208982\n",
      "epoch is: 17\n",
      "0.7089881305208982\n",
      "epoch is: 18\n",
      "0.7089881305208982\n",
      "epoch is: 19\n",
      "0.7089881305208982\n",
      "epoch is: 20\n",
      "0.7201058277552083\n"
     ]
    }
   ],
   "source": [
    "wait_total = 200\n",
    "total_epochs = 6\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    emb = model.g_encode(data).clone()\n",
    "    x, y = model.s_encode(data, emb)  # emb from encode's, i.e., Gconv's output\n",
    "    loss = F.binary_cross_entropy(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return x\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    emb = model.g_encode(data)\n",
    "    for type in [\"val\", \"test\"]:\n",
    "        pred, y = model.s_encode(data, emb, type=type)\n",
    "        pred, y = pred.cpu(), y.cpu()\n",
    "        if type == \"val\":\n",
    "            accs.append(F.binary_cross_entropy(pred, y))\n",
    "            pred = pred.data.numpy()\n",
    "            roc = roc_auc_score(y, pred)\n",
    "            accs.append(roc)\n",
    "            acc = average_precision_score(y, pred)\n",
    "            accs.append(acc)\n",
    "        else:\n",
    "            pred = pred.data.numpy()\n",
    "            roc = roc_auc_score(y, pred)\n",
    "            accs.append(roc)\n",
    "            acc = average_precision_score(y, pred)\n",
    "            accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# train and test\n",
    "for epoch in range(1, total_epochs + 1):\n",
    "    print(\"epoch is:\", epoch)\n",
    "    pred = train()\n",
    "    val_loss, val_roc, val_acc, tmp_test_roc, tmp_test_acc = test()\n",
    "    if val_roc >= best_val_roc:\n",
    "        test_acc = tmp_test_acc\n",
    "        test_roc = tmp_test_roc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_roc = val_roc\n",
    "        best_val_loss = val_loss\n",
    "        wait_step = 0\n",
    "    else:\n",
    "        wait_step += 1\n",
    "        if wait_step == wait_total:\n",
    "            print(\n",
    "                \"Early stop! Min loss: \",\n",
    "                best_val_loss,\n",
    "                \", Max accuracy: \",\n",
    "                best_val_acc,\n",
    "                \", Max roc: \",\n",
    "                best_val_roc,\n",
    "            )\n",
    "            break\n",
    "    print(best_val_roc)\n",
    "# del model\n",
    "# del data\n",
    "# print result\n",
    "\n",
    "# pipeline_acc[Conv_method][data_cnt] = test_acc\n",
    "# pipeline_roc[Conv_method][data_cnt] = test_roc\n",
    "\n",
    "# log = 'Epoch: ' + str(\n",
    "#    total_epochs) + ', dataset name: ' + d_name + ', Method: ' + Conv_method + ' Test pr: {:.4f}, roc: {:.4f} \\n'\n",
    "# print((log.format(pipeline_acc[Conv_method][data_cnt], pipeline_roc[Conv_method][data_cnt])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
